import streamlit as st
import pandas as pd
import google.generativeai as genai
import re

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì™„ì „ì²´ ì˜ë‹¨ì–´ì¥", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ AI ì˜ë‹¨ì–´ì¥ ")

# 2. Gemini ì„¤ì •
try:
    if "gemini" in st.secrets and "api_key" in st.secrets["gemini"]:
        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        model = genai.GenerativeModel('gemini-2.5-flash-lite')
    else:
        st.error("ğŸš¨ Secretsì— API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        model = None
except Exception as e:
    st.error(f"Gemini ì„¤ì • ì˜¤ë¥˜: {e}")

try:
    existing_data = conn.read(worksheet="Sheet1", usecols=[0, 1, 2], ttl=0)
    existing_data = existing_data.dropna(how="all")
    if not existing_data.empty:
        existing_words = existing_data["ë‹¨ì–´"].astype(str).str.strip().tolist()
    else:
        existing_words = []
except:
    existing_data = pd.DataFrame(columns=["ë‹¨ì–´", "ëœ»", "ì˜ˆë¬¸"])
    existing_words = []

# íƒ­ êµ¬ì„±
tab1, tab2 = st.tabs(["ğŸ“š ë‹¨ì–´ì¥ ê´€ë¦¬", "ğŸ§° ì˜ì–´ ê³µë¶€ ë„êµ¬í•¨"])

# ==========================================
# íƒ­ 1: ë‹¨ì–´ì¥
# ==========================================
with tab1:
    with st.expander("ğŸ” ë‹¨ì–´/ìˆ™ì–´ ë¶„ì„ ë° ì¶”ê°€", expanded=True):
        with st.form("search_form", clear_on_submit=True):
            col_input, col_btn = st.columns([4, 1])
            with col_input:
                word_input = st.text_input("ë‹¨ì–´ ë˜ëŠ” ìˆ™ì–´ ì…ë ¥", placeholder="ì˜ˆ: address")
            with col_btn:
                search_submitted = st.form_submit_button("ğŸ” ë¶„ì„")

            if search_submitted and word_input:
                input_word = word_input.strip()
                
                if not model:
                    st.error("AI ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨")
                else:
                    with st.spinner(f"AIê°€ '{input_word}'ë¥¼ ë¶„ì„ ì¤‘..."):
                        try:
                            prompt = f"""
                            Role: Comprehensive English-Korean Dictionary
                            Input: '{input_word}'
                            
                            Task:
                            1. Identify the correct word/phrase (fix typos).
                            2. Select 3 distinct meanings.
                            3. **CRITICAL:** If the word has multiple Parts of Speech (e.g., Noun AND Verb), YOU MUST INCLUDE BOTH TYPES.
                            4. Prefix the Korean meaning with the Part of Speech tag: [ëª…ì‚¬], [ë™ì‚¬] etc.
                            
                            STRICT Output Format:
                            CORRECT_WORD: <Corrected Word>
                            [POS] Korean Meaning @@@ English Example Sentence
                            """
                            response = model.generate_content(prompt)
                            st.session_state['analyzed_result'] = response.text
                            st.session_state['analyzed_word'] = input_word 
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ë¶„ì„ ê²°ê³¼ í™•ì¸
    if 'analyzed_result' in st.session_state and 'analyzed_word' in st.session_state:
        raw_text = st.session_state['analyzed_result']
        
        meanings_list = []
        examples_list = []
        final_word = st.session_state.get('analyzed_word', 'Unknown')
        
        lines = raw_text.strip().split('\n')
        valid_data_lines = []
        
        for line in lines:
            line = line.strip()
            if not line: continue
            
            if line.startswith("CORRECT_WORD:"):
                try:
                    final_word = line.split(":", 1)[1].strip()
                    st.session_state['analyzed_word'] = final_word
                except:
                    pass
            elif "@@@" in line:
                valid_data_lines.append(line)

        for i, line in enumerate(valid_data_lines):
            parts = line.split("@@@", 1)
            raw_meaning = re.sub(r'^[\d\.\-\)\s]+', '', parts[0].strip())
            raw_example = re.sub(r'^[\d\.\-\)\s]+', '', parts[1].strip())
            
            meanings_list.append(f"{i+1}. {raw_meaning}")
            examples_list.append(f"{i+1}. {raw_example}")
        
        default_meaning = '\n'.join(meanings_list)
        default_example = '\n'.join(examples_list)

        if final_word in existing_words:
            st.warning(f"âš ï¸ '{final_word}'ëŠ” ì´ë¯¸ ë‹¨ì–´ì¥ì— ìˆìŠµë‹ˆë‹¤!")
        else:
            st.info(f"ğŸ§ **{final_word}** (ìœ¼)ë¡œ ê²€ìƒ‰ëœ ê²°ê³¼ì…ë‹ˆë‹¤.")
        
        with st.container():
            col1, col2 = st.columns(2)
            with col1:
                final_meaning = st.text_area("ğŸ‡°ğŸ‡· ëœ» (í’ˆì‚¬ í¬í•¨)", value=default_meaning, height=150)
            with col2:
                final_example = st.text_area("ğŸ‡ºğŸ‡¸ ì˜ˆë¬¸", value=default_example, height=150)

            if st.button("ğŸ’¾ ë‹¨ì–´ì¥ì— ì¶”ê°€í•˜ê¸°", type="primary", use_container_width=True):
                if not final_meaning or not final_example:
                    st.warning("ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                elif final_word in existing_words:
                    st.error("ì´ë¯¸ ì €ì¥ëœ ë‹¨ì–´ì…ë‹ˆë‹¤.")
                else:
                    try:
                        current_df = conn.read(worksheet="Sheet1", usecols=[0, 1, 2], ttl=0)
                        new_entry = pd.DataFrame([{
                            "ë‹¨ì–´": final_word,
                            "ëœ»": final_meaning,
                            "ì˜ˆë¬¸": final_example
                        }])
                        updated_data = pd.concat([current_df, new_entry], ignore_index=True)
                        conn.update(worksheet="Sheet1", data=updated_data)
                        
                        st.toast(f"'{final_word}' ì €ì¥ ì„±ê³µ! ğŸ‰")
                        if 'analyzed_word' in st.session_state: del st.session_state['analyzed_word']
                        if 'analyzed_result' in st.session_state: del st.session_state['analyzed_result']
                        st.rerun()
                    except Exception as e:
                        st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    # ëª©ë¡ ë° ë°±ì—…
    st.divider()
    
    col_header, col_buttons = st.columns([2, 1])
    
    with col_header:
        st.subheader(f"ğŸ“ ì €ì¥ëœ ë‹¨ì–´ì¥ ({len(existing_data)}ê°œ)")
        filter_keyword = st.text_input("ğŸ“‚ ë‚´ ë‹¨ì–´ì¥ì—ì„œ ì°¾ê¸°", placeholder="ë‹¨ì–´ ì² ìë‚˜ ëœ»ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”...")

    with col_buttons:
        st.write("")
        st.write("")
        b_col1, b_col2 = st.columns(2)
        with b_col1:
            if not existing_data.empty:
                csv = existing_data.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label="ğŸ’¾ ì—‘ì…€ ë°±ì—…",
                    data=csv,
                    file_name='my_voca_backup.csv',
                    mime='text/csv',
                    type='secondary',
                    use_container_width=True
                )
        with b_col2:
            try:
                sheet_url = st.secrets["connections"]["gsheets"]["spreadsheet"]
            except:
                sheet_url = "https://docs.google.com/spreadsheets"
            st.link_button("ğŸ“ƒ ì‹œíŠ¸ ì—´ê¸°", sheet_url, use_container_width=True)

    if not existing_data.empty:
        if filter_keyword:
            display_data = existing_data[
                existing_data['ë‹¨ì–´'].str.contains(filter_keyword, case=False, na=False) | 
                existing_data['ëœ»'].str.contains(filter_keyword, case=False, na=False)
            ]
        else:
            display_data = existing_data

        if display_data.empty:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for i in sorted(display_data.index, reverse=True):
                row = display_data.loc[i]
                with st.expander(f"ğŸ“– {row['ë‹¨ì–´']}"):
                    
                    # ==========================================================
                    # ğŸ”¥ [ì—¬ê¸°ê°€ ë°”ë€ ë¶€ë¶„] ë³µì‚¬í•˜ê¸° ë°˜ / ì‚¬ì „ ì°¾ê¸° ë°˜
                    # ==========================================================
                    col_copy, col_dict = st.columns([1, 1])
                    
                    with col_copy:
                        st.caption("ë³µì‚¬í•˜ê¸°")
                        st.code(row['ë‹¨ì–´'], language="text")
                        
                    with col_dict:
                        st.caption("ë°œìŒ ë“£ê¸° (ë„¤ì´ë²„ ì‚¬ì „)")
                        # ë„¤ì´ë²„ ì‚¬ì „ ì£¼ì†Œ ë’¤ì— ë‹¨ì–´ë¥¼ ë¶™ì—¬ì„œ ë°”ë¡œ ì´ë™í•˜ê²Œ ë§Œë“¦
                        dict_url = f"https://en.dict.naver.com/#/search?query={row['ë‹¨ì–´']}"
                        st.link_button(f"ğŸ”Š {row['ë‹¨ì–´']} ë°œìŒ ë“£ê¸°", dict_url, use_container_width=True)

                    c1, c2 = st.columns(2)
                    with c1:
                        new_meaning = st.text_area("ëœ»", row['ëœ»'], key=f"m_{i}", height=100)
                    with c2:
                        new_example = st.text_area("ì˜ˆë¬¸", row['ì˜ˆë¬¸'], key=f"e_{i}", height=100)
                    
                    col_save, col_del = st.columns([1, 1])
                    with col_save:
                        if st.button("ğŸ’¾ ìˆ˜ì •", key=f"save_{i}"):
                            existing_data.at[i, "ëœ»"] = new_meaning
                            existing_data.at[i, "ì˜ˆë¬¸"] = new_example
                            conn.update(worksheet="Sheet1", data=existing_data)
                            st.toast("ìˆ˜ì • ì™„ë£Œ!")
                            st.rerun()
                    with col_del:
                        if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"del_{i}"):
                            updated_data = existing_data.drop(index=i)
                            conn.update(worksheet="Sheet1", data=updated_data)
                            st.toast("ì‚­ì œ ì™„ë£Œ!")
                            st.rerun()
    else:
        st.info("ë‹¨ì–´ë¥¼ ê²€ìƒ‰í•´ì„œ ì¶”ê°€í•´ë³´ì„¸ìš”!")

# ==========================================
# íƒ­ 2: ì˜ì–´ ê³µë¶€ ë„êµ¬í•¨
# ==========================================
with tab2:
    st.header("ğŸ§° ìœ ìš©í•œ ì˜ì–´ ë„êµ¬ ëª¨ìŒ")
    st.write("ë‹¨ì–´ì¥ê³¼ í•¨ê»˜ ì“°ë©´ ì¢‹ì€ ì‚¬ì´íŠ¸ë“¤ì„ ëª¨ì•˜ìŠµë‹ˆë‹¤. ë²„íŠ¼ë§Œ ëˆ„ë¥´ì„¸ìš”!")
    
    st.divider()

    col_t1, col_t2 = st.columns(2)

    with col_t1:
        st.subheader("ğŸ¤– AI & ë²ˆì—­")
        st.link_button("ğŸš€ Google Gemini (AI ë¹„ì„œ)", "https://gemini.google.com", type="primary", use_container_width=True)
        st.link_button("ğŸ§  DeepL (ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­)", "https://www.deepl.com/translator", use_container_width=True)

    with col_t2:
        st.subheader("ğŸ“š ì‚¬ì „ & í•™ìŠµ")
        st.link_button("ğŸ¦œ Papago (ë„¤ì´ë²„ ë²ˆì—­)", "https://papago.naver.com", use_container_width=True)
        st.link_button("ğŸ“˜ Naver ì˜ì–´ì‚¬ì „", "https://en.dict.naver.com", use_container_width=True)
    
    st.info("ğŸ’¡ Tip: 'DeepL'ì€ ë‰˜ì•™ìŠ¤ë¥¼ ì‚´ë¦° ë²ˆì—­ì—, 'Papago'ëŠ” í•œêµ­ì–´ ì¡´ëŒ“ë§/ë°˜ë§ êµ¬ë¶„ì— ê°•í•©ë‹ˆë‹¤!")



